{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c50f59",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8bff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d51a",
   "metadata": {},
   "source": [
    "# Types of Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d431c7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0, 1, 2\n",
    "Discrete(3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c041b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11172476, 0.13338836, 0.675468  ],\n",
       "       [0.09634547, 0.6680662 , 0.38782513],\n",
       "       [0.8826869 , 0.14965059, 0.20709646]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An array 3 x 3 (an array that contains 3 arrays with each array containing 3 values)\n",
    "# 0 and 1 are the lower and upper values (the range of where the values will lie)\n",
    "Box(0,1,shape=(3,3)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97c2c68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " array([[0.72381985, 0.75307155, 0.836142  ],\n",
       "        [0.75173223, 0.91596746, 0.18010943],\n",
       "        [0.66017056, 0.07019453, 0.7298493 ]], dtype=float32),\n",
       " array([1, 0, 0, 1], dtype=int8))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrapper 1 that brings spaces together\n",
    "Tuple((Discrete(3), Box(0,1,shape=(3,3)), MultiBinary(4))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a0a0015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('height', 1), ('speed', array([19.978773], dtype=float32))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrapper 2 that brings spaces together\n",
    "Dict({'height':Discrete(2), 'speed':Box(0,100,shape=(1,))}).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "988b3095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contains 4 positions\n",
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2833b443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([5,2,2]).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d44e91",
   "metadata": {},
   "source": [
    "# Building Environment\n",
    "- Build an agent to give us the best shower possible\n",
    "- Random temperature\n",
    "- Agent does not know we prefer the temperature to be between 37 degrees to 39 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5f75621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tap off, tap on, or remains unchanged\n",
    "Discrete(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62d8604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([92.47772], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First way of defining a box space\n",
    "Box(low=np.array([0]), high=np.array([100])).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a5a58d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2043661], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second way of defining a box space\n",
    "Box(low=0, high=100, shape=(1,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de989c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(low=0, high=100, shape=(1,))\n",
    "        # Our temperature\n",
    "        self.state = 38 + random.randint(-3,3)\n",
    "        self.shower_length = 60\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Apply temperature adjustment\n",
    "        self.state += action-1\n",
    "        # Decrease shower time\n",
    "        self.shower_length -= 1\n",
    "        \n",
    "        # Calculate reward\n",
    "        if self.state >= 37 and self.state <= 39:\n",
    "            reward = 1\n",
    "        else:\n",
    "            # Reward can be 0 as well\n",
    "            reward = -1\n",
    "            \n",
    "        if self.shower_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        # Implement viz (optional)\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.array([38+random.randint(-3,3)]).astype(float)\n",
    "        self.shower_length = 60\n",
    "        \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d138e8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    }
   ],
   "source": [
    "# 0: Decreasing shower temp by 1 deg\n",
    "# 1: No change\n",
    "# 2: Increasing shower temp by 1 deg\n",
    "# Based on the action, our state will change to be\n",
    "# As an example: 1 0 would be no change to the temperature\n",
    "value = Discrete(3).sample()\n",
    "print(value, value-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eec24e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15627f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.39811], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a79028ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3146e45a",
   "metadata": {},
   "source": [
    "# Testing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "637c5282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Score: -56\n",
      "Episode 2, Score: -36\n",
      "Episode 3, Score: -26\n",
      "Episode 4, Score: 16\n",
      "Episode 5, Score: 10\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode {}, Score: {}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddcad77",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3ad99a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70594ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5c785c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -2.94    |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -2.85        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045064967 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.733       |\n",
      "|    explained_variance   | 0.00748      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.6         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 99.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -4.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021335785 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.724       |\n",
      "|    explained_variance   | 0.02         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.8         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 73.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -5.88        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037515478 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.697       |\n",
      "|    explained_variance   | -0.0493      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.1         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 83.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -6.66        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029179822 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.708       |\n",
      "|    explained_variance   | 0.0341       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    value_loss           | 75.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -0.74        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 499          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005968355 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | -0.000901    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 76.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 0.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006339756 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.648       |\n",
      "|    explained_variance   | 0.0212       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 42.3         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000913    |\n",
      "|    value_loss           | 78.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 2.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 498          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030957153 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.612       |\n",
      "|    explained_variance   | 0.00356      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 43           |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 84.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 1.78         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016381273 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.6         |\n",
      "|    explained_variance   | 0.0415       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.1         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -9.43e-07    |\n",
      "|    value_loss           | 90.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 1.58         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 485          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030249953 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.61        |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.4         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | 0.000889     |\n",
      "|    value_loss           | 86.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2739a6778b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can run this piece of code everytime on the same model and it keeps learning ; no need for another instantiation of it\n",
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e127f",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2b73b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_path = os.path.join('Training', 'Saved Models', 'Shower_Model_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77072f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e497f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5926e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(shower_path, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d5355e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-24.0, 54.99090833947008)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
